# huggingface-courses

This course teaches you about natural language processing (NLP) using libraries from the Hugging Face ecosystem â€” ðŸ¤— Transformers, ðŸ¤— Datasets, ðŸ¤— Tokenizers, and ðŸ¤— Accelerate â€” as well as the Hugging Face Hub.

- Chapters 1 to 4 provide an introduction to the main concepts of the ðŸ¤— Transformers library. By the end of this part of the course, you will be familiar with how Transformer models work and will know how to use a model from the Hugging Face Hub, fine-tune it on a dataset, and share your results on the Hub!

- Chapters 5 to 8 provide a deep dive into the Datasets Library, the Tokenizers library, a walkthrough of all the common NLP use cases covered by the ðŸ¤— Transformers library, and instructions on debugging and searching the official documentation.

Future chapters are being developed and will be released in the near future. 

I am working on the Pytorch version of the HuggingFace courses, although the syntax for the Tensorflow version is highly similar and I am familiar with Tensorflow syntax (received Tensorflow Developer Certification).
